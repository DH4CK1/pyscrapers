#!/usr/bin/python3

'''
This script scrapes photos from instagram.com

For instance if you see a profile of a user like this:
    https://www.instagram.com/ada_123456789
then the id for this script will be:
    ada_123456789

References:
- http://docs.python-requests.org/en/master
- http://docs.python-guide.org/en/latest/scenarios/scrape
'''

import requests # for post
import lxml.html # for fromstring
import lxml.etree # for tostring
import json # for loads
import shutil # for copyfileobj
import sys # for argv
import logging # for basicConfig, getLogger
import argparse  # for ArgumentParser
import browser_cookie3 # for firefox
import http.client # for HTTPConnection

# code

def get_real_content(r):
    assert r.status_code==200
    strcontent=r.content.decode()
    root=lxml.html.fromstring(strcontent)
    return root

def download_urls(urls):
    cnt=0
    logger.info('got [%d] real urls', len(urls))
    for url in urls:
        logger.debug(url)
        r=requests.get(url, stream=True)
        assert r.status_code==200
        filename='image{0:04}.jpg'.format(cnt)
        with open(filename, 'wb') as f:
            r.raw.decode_content = True
            shutil.copyfileobj(r.raw, f)
        logger.info('written [%s]...', filename)
        cnt+=1

def debug_requests():
    http.client.HTTPConnection.debuglevel=1
    requests_log = logging.getLogger("requests.packages.urllib3")
    requests_log.setLevel(logging.DEBUG)
    requests_log.propagate = True

# register regular expressions with lxml
# this means that we can use regular expression functions like 'match'
# by specifying 're:match' in our xpath expressions
ns = lxml.etree.FunctionNamespace("http://exslt.org/regular-expressions")
ns.prefix = 're'

# set up the logger
logging.basicConfig()
logger=logging.getLogger(__name__)
logger.setLevel(logging.INFO)
#logger.setLevel(logging.DEBUG)

# command line parsing
parser = argparse.ArgumentParser(
        description='''download photos from facebook'''
)
parser.add_argument(
        '-i',
        '--id', 
        help='''id of the user to download the albums of
        For instance if you see a url like this:
            https://www.instagram.com/ada_123456789
        then the id for this script will be:
            ada_123456789
        '''
)
parser.add_argument(
        '-d',
        '--debug',
        help='debug requests',
        default=False,
        action='store_true',
)
args = parser.parse_args()
if args.id is None:
    parser.error('-i/--id must be given')
if args.debug:
    debug_requests()

url='https://www.instagram.com/{id}/'.format(id=args.id)
logger.debug('url is [%s]', url)
r = requests.get(url)
root = get_real_content(r)

urls=[]
e_a = root.xpath('//script[re:match(text(), "^window._sharedData")]')
assert len(e_a)==1
e_a = e_a[0]
data = e_a.text
json_text = data[data.find('{'):data.rfind('}')+1]
#print(json_text)
d=json.loads(json_text)
l=d['entry_data']['ProfilePage']
assert(len(l)==1)
c=l[0]["user"]
urls.append(c['profile_pic_url_hd'])
user_id=c['id']
#json.dump(c, sys.stdout, indent=4)
list_node=c['media']['nodes']
for x in list_node:
    urls.append(x['display_src'])

download_urls(urls)
